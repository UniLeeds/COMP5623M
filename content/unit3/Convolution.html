<!doctype html>
<html lang="en" class="no-js">

<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">




    <link rel="shortcut icon" href="../../img/favicon.jpg">
    <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-6.2.4">



    <title>Convolution - Artificial Intelligence</title>



    <link rel="stylesheet" href="../../assets/stylesheets/main.15aa0b43.min.css">


    <link rel="stylesheet" href="../../assets/stylesheets/palette.75751829.min.css">







    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,400,400i,700%7C&display=fallback">
    <style>
        body,
        input {
            font-family: "Inter", -apple-system, BlinkMacSystemFont, Helvetica, Arial, sans-serif
        }

        code,
        kbd,
        pre {
            font-family: "", SFMono-Regular, Consolas, Menlo, monospace
        }
    </style>




    <link rel="stylesheet" href="../../css/extra.css">





</head>







<body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">



    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">


        <a href="#convolution" class="md-skip">
          Skip to content
        </a>

    </div>
    <div data-md-component="announce">

        <aside class="md-announce">
            <div class="md-announce__inner md-grid md-typeset">

                <div id="versionIndicator"> <b>Version:</b>27.10.21.a </div>
                <img id="customlogo" src="../../img/logo.svg" alt="University of Leeds logo.">

            </div>
        </aside>

    </div>





    <header class="md-header" data-md-component="header">
        <nav class="md-header-nav md-grid" aria-label="Header">
            <a href="../../index.html" title="Artificial Intelligence" class="md-header-nav__button md-logo" aria-label="Artificial Intelligence">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
            <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
            <div class="md-header-nav__title" data-md-component="header-title">
                <div class="md-header-nav__ellipsis">
                    <div class="md-header-nav__topic">
                        <span class="md-ellipsis">
            Artificial Intelligence
          </span>
                    </div>
                    <div class="md-header-nav__topic">
                        <span class="md-ellipsis">
            
              Convolution
            
          </span>
                    </div>
                </div>
            </div>

            <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>

            <div class="md-search" data-md-component="search" role="dialog">
                <label class="md-search__overlay" for="__search"></label>
                <div class="md-search__inner" role="search">
                    <form class="md-search__form" name="search">
                        <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
                        <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
                        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
                    </form>
                    <div class="md-search__output">
                        <div class="md-search__scrollwrap" data-md-scrollfix>
                            <div class="md-search-result" data-md-component="search-result">
                                <div class="md-search-result__meta">
                                    Initializing search
                                </div>
                                <ol class="md-search-result__list"></ol>
                            </div>
                        </div>
                    </div>
                </div>
            </div>


        </nav>
    </header>

    <div class="md-container" data-md-component="container">




        <main class="md-main" data-md-component="main">
            <div class="md-main__inner md-grid">



                <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                    <div class="md-sidebar__scrollwrap">
                        <div class="md-sidebar__inner">







                            <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
                                <label class="md-nav__title" for="__drawer">
    <a href="../../index.html" title="Artificial Intelligence" class="md-nav__button md-logo" aria-label="Artificial Intelligence">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    Artificial Intelligence
  </label>

                                <ul class="md-nav__list" data-md-scrollfix>







                                    <li class="md-nav__item">
                                        <a href="../../index.html" class="md-nav__link">
      Introduction
    </a>
                                    </li>








                                    <li class="md-nav__item">
                                        <a href="../unit1/Optimisation.html" class="md-nav__link">
      Optimisation
    </a>
                                    </li>








                                    <li class="md-nav__item">
                                        <a href="../unit2/LinearClassifier.html" class="md-nav__link">
      Linear classifier
    </a>
                                    </li>








                                    <li class="md-nav__item">
                                        <a href="../unit2/Performance.html" class="md-nav__link">
      Measuring classifier performance
    </a>
                                    </li>








                                    <li class="md-nav__item">
                                        <a href="../unit2/MultiLayerNetworks.html" class="md-nav__link">
      Multilayer networks
    </a>
                                    </li>










                                    <li class="md-nav__item md-nav__item--active">

                                        <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">




                                        <label class="md-nav__link md-nav__link--active" for="__toc">
        Convolution
        <span class="md-nav__icon md-icon"></span>
      </label>

                                        <a href="Convolution.html" class="md-nav__link md-nav__link--active">
      Convolution
    </a>


                                        <nav class="md-nav md-nav--secondary" aria-label="Table of contents">





                                            <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
                                            <ul class="md-nav__list" data-md-scrollfix>

                                                <li class="md-nav__item">
                                                    <a href="#image-smoothing-using-cross-correlation" class="md-nav__link">
    Image smoothing using cross-correlation
  </a>

                                                </li>

                                                <li class="md-nav__item">
                                                    <a href="#convolution_1" class="md-nav__link">
    Convolution
  </a>

                                                </li>

                                                <li class="md-nav__item">
                                                    <a href="#retinotopic-maps-in-natural-vision-systems" class="md-nav__link">
    Retinotopic maps in natural vision systems
  </a>

                                                </li>

                                                <li class="md-nav__item">
                                                    <a href="#feature-detection-using-convolution" class="md-nav__link">
    Feature detection using convolution
  </a>

                                                </li>

                                                <li class="md-nav__item">
                                                    <a href="#references" class="md-nav__link">
    References
  </a>

                                                </li>

                                            </ul>

                                        </nav>

                                    </li>








                                    <li class="md-nav__item">
                                        <a href="CNN.html" class="md-nav__link">
      Convolutional neural networks
    </a>
                                    </li>








                                    <li class="md-nav__item">
                                        <a href="Segmentation.html" class="md-nav__link">
      Image segmentation
    </a>
                                    </li>








                                    <li class="md-nav__item">
                                        <a href="../unit4/Introduction.html" class="md-nav__link">
      Sequential data
    </a>
                                    </li>








                                    <li class="md-nav__item">
                                        <a href="../unit4/RNN.html" class="md-nav__link">
      Recurrent neural networks
    </a>
                                    </li>








                                    <li class="md-nav__item">
                                        <a href="../unit4/TextClassification.html" class="md-nav__link">
      Text classification
    </a>
                                    </li>








                                    <li class="md-nav__item">
                                        <a href="../unit4/Transformers.html" class="md-nav__link">
      Transformers
    </a>
                                    </li>








                                    <li class="md-nav__item">
                                        <a href="../unit5/RelationalData.html" class="md-nav__link">
      Relational data
    </a>
                                    </li>








                                    <li class="md-nav__item">
                                        <a href="../unit5/GNN.html" class="md-nav__link">
      Graph neural networks
    </a>
                                    </li>








                                    <li class="md-nav__item">
                                        <a href="../unit6/GAN.html" class="md-nav__link">
      Generative adversarial networks
    </a>
                                    </li>








                                    <li class="md-nav__item">
                                        <a href="../unit6/Cyclegan.html" class="md-nav__link">
      Image-to-image translation
    </a>
                                    </li>


                                </ul>
                            </nav>
                        </div>
                    </div>
                </div>



                <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                    <div class="md-sidebar__scrollwrap">
                        <div class="md-sidebar__inner">

                            <nav class="md-nav md-nav--secondary" aria-label="Table of contents">





                                <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
                                <ul class="md-nav__list" data-md-scrollfix>

                                    <li class="md-nav__item">
                                        <a href="#image-smoothing-using-cross-correlation" class="md-nav__link">
    Image smoothing using cross-correlation
  </a>

                                    </li>

                                    <li class="md-nav__item">
                                        <a href="#convolution_1" class="md-nav__link">
    Convolution
  </a>

                                    </li>

                                    <li class="md-nav__item">
                                        <a href="#retinotopic-maps-in-natural-vision-systems" class="md-nav__link">
    Retinotopic maps in natural vision systems
  </a>

                                    </li>

                                    <li class="md-nav__item">
                                        <a href="#feature-detection-using-convolution" class="md-nav__link">
    Feature detection using convolution
  </a>

                                    </li>

                                    <li class="md-nav__item">
                                        <a href="#references" class="md-nav__link">
    References
  </a>

                                    </li>

                                </ul>

                            </nav>
                        </div>
                    </div>
                </div>


                <div class="md-content">
                    <article class="md-content__inner md-typeset">



                        <h1 id="convolution">Convolution</h1>
                        <h2 id="image-smoothing-using-cross-correlation">Image smoothing using cross-correlation</h2>
                        <p>There is often a need to smooth the intensity values over the pixels that make up an image. Smoothing can remove small scale detail such as random noise. To illustrate this, consider a 2D array (matrix) of mean intensity values
                            obtained by taking the mean of the red, green and blue colour channels at each pixel.</p>
                        <div class="arithmatex">\[ f = \frac{r+g+b}{3} \]</div>
                        <p>For the colour image on the left, the mean intensity image is depicted on the right, rendered using a <em>grey</em> colour map. Remember that displaying an image requires three values for each pixel: the RGB values. The colour
                            map defines these values for shades of grey in the interval [0,1].</p>
                        <figure role="group">
                            <img src="images/picture1.png" alt="Mean intensity image (right) from colour image (left)." />
                            <figcaption>
                                <p><strong>Figure 1.</strong> From a colour image (left), generate a mean intensity image and display using a grey colormap (right). </p>
                            </figcaption>
                        </figure>

                        <p>A simple way to smooth the image is to replace the value at each pixel by the mean of the neighbouring values (including the current pixel). This can be computed using a <span class="arithmatex">\(3\times 3\)</span> array (referred
                            to as a <em>kernel</em> or <em>mask</em>) containing the value <span class="arithmatex">\(\frac{1}{9}\)</span> in each location.</p>
                        <figure role="group">
                            <img src="images/picture2.svg" alt="Smoothing kernel." />
                            <figcaption>
                                <p><strong>Figure 2.</strong> A 3x3 kernel for smoothing an image.</p>
                            </figcaption>
                        </figure>

                        <p>The centre of the kernel is placed at each location of the image. Each value in the kernel is then multiplied by the value beneath and the resulting products are summed, with this value being inserted into a new image at the corresponding
                            position. We refer to this process as <em>cross-correlation</em>.</p>
                        <p>The process is nicely illustrated by these animations from: <a href="https://github.com/vdumoulin/conv_arithmetic" target="_blank">https://github.com/vdumoulin/conv_arithmetic</a></p>
                        <figure role="group">
                            <img src="images/no_padding_no_strides.gif" alt="Animation of correlation with no padding." />
                            <figcaption>
                                <p><strong>Figure 3.</strong> Illustration of correlation with no padding. </p>
                            </figcaption>
                        </figure>

                        <p>Because the kernel can't be centred on the boundary rows and columns of the image, there are fewer rows and columns in the output than the input. To make the output image the same size as the input, it is common practice to expand
                            the original image with additional rows and columns on the left and right and on the top and bottom. This means that the kernel can be centred at all pixels locations of the original image. The additional rows and columns are
                            normally filled with zeros.</p>
                        <figure role="group">
                            <img src="images/same_padding_no_strides.gif" alt="Animation of correlation with zero padding." />
                            <figcaption>
                                <p><strong>Figure 4.</strong> Illustration of correlation with zero padding.</p>
                            </figcaption>
                        </figure>

                        <p>Two variations of the procedure are to move the kernel one or more steps at a time across the columns and down the rows. We call the step size the <em>stride</em>. For example, in the following correlation with zero padding, the
                            stride is two.</p>
                        <figure role="group">
                            <img src="images/padding_strides.gif" alt="Animation of correlation with stride of 2." />
                            <figcaption>
                                <p><strong>Figure 5.</strong> Illustration of correlation with stride of 2.</p>
                            </figcaption>
                        </figure>

                        <p>Another variation is to interspace the values in the kernel as they are applied to the image values. We refer to the degree of interspacing as the <em>dilation</em>. For example, in the following illustration the dilation is two.</p>
                        <figure role="group">
                            <img src="images/dilation.gif" alt="Animation of correlation with dilation of 2." />
                            <figcaption>
                                <p><strong>Figure 6.</strong> Illustration of correlation with dilation of 2.</p>
                            </figcaption>
                        </figure>

                        <p>The result of cross-correlation of an image <span class="arithmatex">\(f(x,y)\)</span> with a kernel <span class="arithmatex">\(h(u,v), -1 \le u,v \le 1\)</span> can be expressed as:</p>
                        <div class="arithmatex">\[ f'(x,y)= \sum_{u=-1}^1 \sum_{v=-1}^1 h(u,v)f(x+u,y+v) \]</div>
                        <p>In practice, to smooth an image, the kernel will normally have the shape of a 2-D Gaussian function, which gives more emphasis to the centre values and progressively less emphasis away from the centre. The definition of a 2-D Gaussian
                            function centred about the origin is as follows:</p>
                        <div class="arithmatex">\[ h(u,v) = \frac 1{2\pi\sigma^2} e^{-(u^2+v^2)/2\sigma^2} \]</div>
                        <p>This is defined over the whole of the u-v plane (out to infinity) such that the area underneath the surface sums to one. To build an nxn kernel from this function, we sample at integer values over an nxn grid. To smooth the image
                            without brightening or darkening the result, it is important the weights add up to one. To ensure this is the case, we normalise the kernel by dividing every weight by the sum of the weights. Such a kernel is shown below, where
                            each of the values should be multiplied by 0.001 as illustrated:</p>
                        <figure role="group">
                            <img src="images/gaussianmask.svg" alt="Gaussian weights in a 5x5 kernel." />
                            <figcaption>
                                <p><strong>Figure 7.</strong> Gaussian weights in a 5x5 kernel.</p>
                            </figcaption>
                        </figure>

                        <p>The amount of smoothing is determined by the <em>spread</em> of the Gaussian. This spread is controlled by the value of <span class="arithmatex">\(\sigma\)</span> (sigma). This is also the standard deviation of the Gaussian. The
                            following diagram shows the result of correlation with a Gaussian kernel for three different standard deviations.</p>
                        <figure role="group">
                            <img src="images/smoothing.jpg" alt="Original image with three further images resulting from correlation with Gaussian kernels for standard deviations 1, 2 and 4." />
                            <figcaption>
                                <p><strong>Figure 8.</strong> Correlation with Gaussian kernels for standard deviations 1, 2 and 4.</p>
                            </figcaption>
                        </figure>

                        <p>The three corresponding kernels are illustrated in the diagram below:</p>
                        <figure role="group">
                            <img src="images/gaussianmasks.png" alt="Three Gaussian kernels with increasing spread" />
                            <figcaption>
                                <p><strong>Figure 9.</strong> Three Gaussian kernels used for the smoothing depicted in Figure 8.</p>
                            </figcaption>
                        </figure>

                        <h2 id="convolution_1">Convolution</h2>
                        <p>If we rotate the kernel by a half turn (180 degrees) before applying cross-correlation, the resulting operation is known as <em>convolution</em>. The convolution of an image <span class="arithmatex">\(f\)</span> with a kernel
                            <span
                                class="arithmatex">\(h\)</span> is written as <span class="arithmatex">\(h*f\)</span> for short.</p>
                        <p>Note that a Gaussian kernel of the form above is invariant under any rotation. Therefore cross-correlation and convolution with a Gaussian kernel amount to the same thing.</p>
                        <p>From now on, we will refer to the process as convolution.</p>
                        <h2 id="retinotopic-maps-in-natural-vision-systems">Retinotopic maps in natural vision systems</h2>
                        <p>The process of convolution computes a new value at each location from local values according to the scalar values in the kernel. The local nature of this computation is mirrored in the human visual system. This is illustrated in
                            experiments reported in 2003 by Dougherty et al. [1].</p>
                        <p>The visual cortex at the back of the brain contains regions of neural cells (neurons) that seem to be laid out in correspondence with the visual field (image received by the eye). Functional magnetic resonance imaging (fMRI) is
                            used to produce images of the brain where pixel intensities correspond to blood flow, which in turn is a measure of the activity levels of neurons. These regions are referred to as <em>retinotopic maps</em>. In an experiment
                            with human subjects, a circular chequered pattern (shown top-left in the figure below) expands in an outward direction. As the chequered pattern moves over the visual field, different parts of the visual cortex become stimulated.
                            Remarkably, the areas of stimulation seem to be organised as maps in correspondence with the retinal images. We call these <em>retinotopic maps</em>. In the diagram below, the surface of the cortex is colour coded with the
                            size of annulus that stimulates that location.</p>
                        <figure role="group">
                            <img src="images/retinatopicmaps.jpg" alt="Images of fMRI response in the visual cortex to expanding and rotating chequered stimuli" />
                            <figcaption>
                                <p><strong>Figure 10.</strong> Functional magnetic resonance images showing localised response to expanding and rotating stimuli.</p>
                                <p>From <em>Dougherty et al., 2003 [1]</em>.</p>
                            </figcaption>
                        </figure>

                        <p>The colour coding is shown to the right of the displayed pattern. Similarly, a rotating pattern (top-right), and associated colour coding, causes a gradual variation orthogonal to the first in the visual cortex (bottom-right image).
                            A given location in this region of the cortex therefore corresponds with a specific radial distance and angle of a stimulus falling onto the retina. In other words, it provides polar coordinates for the stimulus.</p>
                        <figure role="group">
                            <img src="images/polar.svg" alt="Polar coordindates for points in 2-D." />
                            <figcaption>
                                <p><strong>Figure 11.</strong> Polar coordinates represent the position of a point as an angle and a distance from the origin.</p>
                            </figcaption>
                        </figure>

                        <p>Overall, this region of the visual cortex is in one-to-one correspondence with the retinal; it is a retinotopic map.</p>
                        <p>In the diagram below, nine retinotopic maps can be seen in the visual cortex. Area V1 is known as the <em>primary visual cortex</em>.</p>
                        <figure role="group">
                            <img src="images/multiplemaps.jpg" alt="Multiple retinotopic maps." aria-describedby="fig-12-description" />
                            <figcaption>
                                <p><strong>Figure 12.</strong> The locations of nine retinopic maps. </p>
                                <p>From <em>Wandell et al.</em> [2].</p>
                                <button class="accordion-button">View image description</button>
                                <div class="accordion-panel">
                                    <div id="fig-12-description">
                                        <p>Four views of the visual cortex showing nine colour-coded regions where there are retinotopic maps. </p>
                                    </div>
                                </div>
                            </figcaption>
                        </figure>

                        <p>An original set of experiments from the pioneering work of Hubel and Wiesel in 1960 [3] used electrical probes to measure the activity in different clusters of neurons within the visual cortex of animals in response to different
                            kinds of stimulus. </p>
                        <p>These experiments indicated that the brain contains neurons that fire more rapidly when specific visual patterns appear at fixed locations in the visual field. Some cells respond to intensity edges in specific orientations, and
                            others to bar shapes in specific orientations. Some cells only respond to edges or bars that are moving ‘sideways’ across the visual field.</p>
                        <p>Here is an original video of this work.</p>
                        <iframe title="Hubel & Weisel (1960) Visual Cortex: Mapping receptive fields" width="450" height="300" frameborder="0" scrolling="auto" marginheight="0" marginwidth="0" src="https://mymedia.leeds.ac.uk/Mediasite/Play/2dd3058c72164e6dbcb9294d90bbad4e1d"
                            allowfullscreen msallowfullscreen allow="fullscreen"></iframe>

                        <p>From work like this, the visual cortex seems to be producing maps for different visual features present in the visual field. We refer to these as <em>feature maps</em>. We now know that the brain adapts the patterns detected to
                            the patterns that are observed in the visual field – we might say that the patterns are learned. This property of the neural apparatus is referred to as plasticity.</p>
                        <p>It turns out that such maps can be easily produced using convolution with appropriately chosen kernels. Moreover, we can learn the values in these kernels from natural images.</p>
                        <h2 id="feature-detection-using-convolution">Feature detection using convolution</h2>
                        <p>The following images have been obtained by convolving the arch image with the four <span class="arithmatex">\(3 \times 3\)</span> kernels shown above each image. Locations in the image for which the value computed by convolution
                            is above 0.5 are shown in white. The four convolutions produce the highest values for intensity edges in four orientations. The vertical structure in the arch is visible with the top two kernels and the horizontal structure
                            elsewhere is visible with the bottom two kernels. In fact, one of the vertical convolutions could be obtained by negating the sign of the other vertical convolution and likewise for the pair of vertical convolutions. However,
                            we have retained all four convolutions to emphasise the difference in the patterns of image intensity. The kernels used here are normally associated with the name <em>Sobel</em> from the early days of computer vision.</p>
                        <figure role="group">
                            <img src="images/fourmasks.svg" alt="Locations of large responses in the convolution with each of four kernels." />
                            <figcaption>
                                <p><strong>Figure 13.</strong> The four images show locations where there is a large positive response to convolution with the 3x3 kernel shown above each image. </p>
                            </figcaption>
                        </figure>

                        <p>The following image shows the strongest response from the four convolutions at each pixel location using a unique colour for each kernel (shown in the corners of the images above).</p>
                        <figure role="group">
                            <img src="images/composite.svg" alt="The dominant response of the four convolutions at each location, using a unique colour for each kernel." />
                            <figcaption>
                                <p><strong>Figure 14.</strong> The dominant response of the four convolutions at each location, using a unique colour for each kernel.</p>
                            </figcaption>
                        </figure>

                        <h2 id="references">References</h2>
                        <p>[1] <a href="http://journalofvision.org/3/10/1/"><em>Dougherty, R. F., et al.  (2003). Visual field representations and locations of visual areas V&frac12;/3 in human visual cortex. Journal of Vision, 3(10):1, 586-598</em></a></p>
                        <p>[2] <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1569486/"><em>Wandell et al. (2005) Visual Field Map Clusters in Human Cortex, Phil. Trans. of the Royal Society London, vol. 360, pp. 693-707.</em></a></p>
                        <p>[3] <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1359523/"><em>D N Hubel and T H Wiesel (1960), Journal of Physiology, 160</em></a>.</p>







                    </article>
                </div>
            </div>
        </main>


        <footer class="md-footer">

            <div class="md-footer-nav">
                <nav class="md-footer-nav__inner md-grid" aria-label="Footer">

                    <a href="../unit2/MultiLayerNetworks.html" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
                        <div class="md-footer-nav__button md-icon">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
                        </div>
                        <div class="md-footer-nav__title">
                            <div class="md-ellipsis">
                                <span class="md-footer-nav__direction">
                  Previous
                </span> Multilayer networks
                            </div>
                        </div>
                    </a>


                    <a href="CNN.html" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
                        <div class="md-footer-nav__title">
                            <div class="md-ellipsis">
                                <span class="md-footer-nav__direction">
                  Next
                </span> Convolutional neural networks
                            </div>
                        </div>
                        <div class="md-footer-nav__button md-icon">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
                        </div>
                    </a>

                </nav>
            </div>

            <div class="md-footer-meta md-typeset">
                <div class="md-footer-meta__inner md-grid">
                    <div class="md-footer-copyright">

                        <div class="md-footer-copyright__highlight">
                            Copyright © University of Leeds
                        </div>

                        Made with
                        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
                    </div>

                </div>
            </div>
        </footer>

    </div>

    <script src="../../assets/javascripts/vendor.93c04032.min.js"></script>
    <script src="../../assets/javascripts/bundle.83e5331e.min.js"></script>
    <script id="__lang" type="application/json">
        {
            "clipboard.copy": "Copy to clipboard",
            "clipboard.copied": "Copied to clipboard",
            "search.config.lang": "en",
            "search.config.pipeline": "trimmer, stopWordFilter",
            "search.config.separator": "[\\s\\-]+",
            "search.placeholder": "Search",
            "search.result.placeholder": "Type to start searching",
            "search.result.none": "No matching documents",
            "search.result.one": "1 matching document",
            "search.result.other": "# matching documents",
            "search.result.more.one": "1 more on this page",
            "search.result.more.other": "# more on this page",
            "search.result.term.missing": "Missing"
        }
    </script>

    <script>
        app = initialize({
            base: "../..",
            features: ['navigation.sections'],
            search: Object.assign({
                worker: "../../assets/javascripts/worker/search.8c7e0a7e.min.js"
            }, typeof search !== "undefined" && search)
        })
    </script>

    <script src="../../javascript/tablecontentsoverride.js"></script>

    <script src="../../javascript/config.js"></script>

    <script src="../../javascript/interactive-elements.js"></script>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</body>

</html>